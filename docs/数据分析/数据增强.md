---
sort: 4
---

# æ•°æ®å¢å¼º

> æŒç»­æ›´æ–°ä¸­


* [ğŸ”¨ç®—æ³•å¼€å‘æ‰‹å†Œ](https://kg-nlp.github.io/Algorithm-Project-Manual/æ•°æ®åˆ†æ/æ•°æ®å¢å¼º.html)

* [ğŸ”¨ä¸ªäººçŸ¥ä¹](https://www.zhihu.com/people/zhangyj-n)

## [nlpcda](https://github.com/425776024/nlpcda)

* NLP Chinese Data Augmentation ä¸€é”®ä¸­æ–‡æ•°æ®å¢å¼ºå·¥å…·
    * 1.éšæœºå®ä½“æ›¿æ¢
    * 2.è¿‘ä¹‰è¯
    * 3.è¿‘ä¹‰è¿‘éŸ³å­—æ›¿æ¢
    * 4.éšæœºå­—åˆ é™¤ï¼ˆå†…éƒ¨ç»†èŠ‚ï¼šæ•°å­—æ—¶é—´æ—¥æœŸç‰‡æ®µï¼Œå†…å®¹ä¸ä¼šåˆ ï¼‰
    * 5.NERç±» BIO æ•°æ®å¢å¼º
    * 6.éšæœºç½®æ¢é‚»è¿‘çš„å­—ï¼šç ”è¡¨ç©¶æ˜ï¼Œæ±‰å­—åºé¡ºå¹¶ä¸å®šä¸€å½±å“æ–‡å­—çš„é˜…è¯»ç†è§£<<æ˜¯ä¹±åºçš„
    * 7.ä¸­æ–‡ç­‰ä»·å­—æ›¿æ¢ï¼ˆ1 ä¸€ å£¹ â‘ ï¼Œ2 äºŒ è´° â‘¡ï¼‰
    * 8.ç¿»è¯‘äº’è½¬å®ç°çš„å¢å¼º
    * 9.ä½¿ç”¨simbertåšç”Ÿæˆå¼ç›¸ä¼¼å¥ç”Ÿæˆ

## [paddle dataaug](https://github.com/PaddlePaddle/PaddleNLP/blob/develop/docs/dataaug.md)
* 1. è¯çº§åˆ«æ•°æ®å¢å¼ºç­–ç•¥
    * 1.1 è¯æ›¿æ¢
    * 1.2 è¯æ’å…¥
    * 1.3 è¯åˆ é™¤
    * 1.4 è¯äº¤æ¢
* 2. å¥å­çº§åˆ«æ•°æ®å¢å¼ºç­–ç•¥
    * 2.1 åŒä¹‰å¥ç”Ÿæˆ
    * 2.2 å¥å­å›è¯‘
    * 2.3 å¥å­æ‘˜è¦
    * 2.4 å¥å­ç»­å†™
* 3. å­—çº§åˆ«æ•°æ®å¢å¼ºç­–ç•¥
    * 3.1 å­—æ›¿æ¢
    * 3.2 å­—æ’å…¥
    * 3.3 å­—åˆ é™¤
    * 3.4 å­—äº¤æ¢
* 4. æ–‡æ¡£ä¸€é”®å¢å¼º

## [GENIUS](https://github.com/beyondguo/genius)

> æœ‰å¤§æ¨¡å‹åè¿™ä¸ªå¯ä»¥å¿½ç•¥ä¸ç”¨äº†

``` python
from transformers import pipeline
## 1. load the model with the huggingface `pipeline`
genius = pipeline("text2text-generation", model='beyond/genius-base-chinese', device=0)


## 2. provide a sketch (joint by <mask> tokens)
# sketch_list = ["a##[MASK]b[MASK]"]
  
## 3. here we go!
# generated_text = genius(sketch, num_beams=3, do_sample=True, max_length=64)[0]['generated_text']
for sketch in tqdm(sketch_list):
    generated_text = genius(sketch, top_k=1,num_beams=1, do_sample=True, max_length=64)[0]['generated_text']
    generated_text_list = generated_text.replace(' ', '').split('##')
    generated_text = generated_text_list[1]
    label = generated_text_list[0]
    # print(generated_text)
    total_list.append([generated_text,label])
fw = open(os.path.join(finetuning_path,'finetuning_train.txt'),'w')
for i in total_list:
    fw.write(i[0]+'\t'+i[1]+'\n')
fw.close()
```

## åŸºäºå¤§æ¨¡å‹çš„åŒä¹‰å¥ç”Ÿæˆ

> æœ¬æ¬¡ä½¿ç”¨ChatGLM2-6B
[ChatGLMå·¥ç¨‹åˆ†æ](https://kg-nlp.github.io/Algorithm-Project-Manual/%E5%A4%A7%E6%A8%A1%E5%9E%8B/ChatGLM%E5%B7%A5%E7%A8%8B%E5%88%86%E6%9E%90.html)

```python
import requests
import json

headers = {
        "Content-Type": "application/json"
    }

def get_chatglm_info(data: dict) -> dict:
    raw_data = json.dumps(data)
    res = requests.post("http://10.0.79.103:7030/chatglm", headers=headers, data=raw_data)  # ChatGLMè®¿é—®

    result = json.loads(res.text)
    # print(json.dumps(result, indent=False, ensure_ascii=False))
    return result
def llm_enhance_cost():
    df_train_plan = pd.read_excel('è®­ç»ƒé›†.xlsx').fillna('')
    total_list = []
    for ind,raw in tqdm(df_train_plan.iterrows()):
        raw = dict(raw)
        upper_task_name = raw['task']
        if not upper_task_name:
            continue
        task_name = raw['content']
        if len(task_name) > 20:
            content = task_name.replace('\n',',')
            prompt = 'å¯¹"%s"è¿™å¥è¯,é€šè¿‡åŒä¹‰è¯æ›¿æ¢,è¾“å‡º2æ¡è¯­ä¹‰ç›¸åŒçš„å¥å­'%content
            chatglm_data = {
                "prompt": prompt,
                "history": [],
                "max_length": "",
                "top_p": "",
                "temperature": ""
            }
            result = get_chatglm_info(chatglm_data)
            response = result['response'].split('\n')
            for i in response:
                temp = copy.deepcopy(raw)
                temp['content'] = i
                total_list.append(list(temp.values()))
    df = pd.DataFrame(total_list,columns=df_train_plan.columns.tolist())
    df.to_excel('å¢å¼ºæ•°æ®.xlsx',index=False)
```
## æ ¹æ®ä¸šåŠ¡ä¿¡æ¯é’ˆå¯¹æ€§æ‰©å……

## å‚è€ƒ
* [æ ‡æ³¨æ ·æœ¬å°‘æ€ä¹ˆåŠï¼Ÿã€Œæ–‡æœ¬å¢å¼º+åŠç›‘ç£å­¦ä¹ ã€æ€»ç»“ï¼ˆä»PseudoLabelåˆ°UDA/FixMatchï¼‰](https://zhuanlan.zhihu.com/p/146777068)